{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95bad4fd-26a1-416f-9007-efcbec231d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree using ID3:\n",
      "{'Whether': {'Cloudy': {'Temperature': {'High': 'Yes', 'Low': {'Wind': {'High': 'Yes', 'Normal': 'No'}}}}, 'Rain': {'Temperature': {'High': 'Yes', 'Low': 'Yes', 'Normal': {'Wind': {'High': 'Yes', 'Normal': 'No'}}}}, 'Sunny': {'Temperature': {'High': 'No', 'Low': 'Yes', 'Normal': {'Wind': {'High': 'Yes', 'Normal': 'No'}}}}}}\n"
     ]
    }
   ],
   "source": [
    "# Required libraries for ID3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Dataset\n",
    "data = {\n",
    "    'Whether': ['Sunny', 'Rain', 'Cloudy', 'Sunny', 'Sunny', 'Cloudy', 'Rain', 'Rain', 'Sunny', 'Cloudy', 'Rain', 'Sunny'],\n",
    "    'Temperature': ['High', 'Normal', 'High', 'High', 'Low', 'Low', 'Normal', 'Low', 'Normal', 'Low', 'High', 'Normal'],\n",
    "    'Wind': ['High', 'High', 'Normal', 'High', 'Normal', 'High', 'Normal', 'Normal', 'High', 'Normal', 'High', 'Normal'],\n",
    "    'Play': ['No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No']\n",
    "}\n",
    "\n",
    "# Convert dataset into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate entropy\n",
    "def entropy(target_col):\n",
    "    elements, counts = np.unique(target_col, return_counts=True)\n",
    "    entropy_val = 0\n",
    "    for i in range(len(elements)):\n",
    "        p_i = counts[i] / sum(counts)\n",
    "        entropy_val += -p_i * math.log2(p_i)\n",
    "    return entropy_val\n",
    "\n",
    "# Function to calculate information gain\n",
    "def information_gain(data, split_attribute, target_attribute='Play'):\n",
    "    # Calculate the entropy of the whole dataset\n",
    "    total_entropy = entropy(data[target_attribute])\n",
    "    \n",
    "    # Calculate the weighted entropy for the split attribute\n",
    "    values, counts = np.unique(data[split_attribute], return_counts=True)\n",
    "    weighted_entropy = 0\n",
    "    for i in range(len(values)):\n",
    "        subset = data[data[split_attribute] == values[i]]\n",
    "        weighted_entropy += (counts[i] / np.sum(counts)) * entropy(subset[target_attribute])\n",
    "    \n",
    "    # Calculate the information gain\n",
    "    info_gain = total_entropy - weighted_entropy\n",
    "    return info_gain\n",
    "\n",
    "# ID3 algorithm implementation\n",
    "def id3(data, original_data, features, target_attribute='Play', parent_node_class=None):\n",
    "    # If all target values are the same, return that class\n",
    "    if len(np.unique(data[target_attribute])) == 1:\n",
    "        return np.unique(data[target_attribute])[0]\n",
    "    \n",
    "    # If dataset is empty, return the majority class of the original dataset\n",
    "    elif len(data) == 0:\n",
    "        return np.unique(original_data[target_attribute])[np.argmax(np.unique(original_data[target_attribute], return_counts=True)[1])]\n",
    "    \n",
    "    # If no features are left, return the majority class of the current dataset\n",
    "    elif len(features) == 0:\n",
    "        return parent_node_class\n",
    "    \n",
    "    # Otherwise, proceed with ID3\n",
    "    else:\n",
    "        # Record the majority class at the parent node\n",
    "        parent_node_class = np.unique(data[target_attribute])[np.argmax(np.unique(data[target_attribute], return_counts=True)[1])]\n",
    "        \n",
    "        # Calculate the information gain for each feature\n",
    "        info_gains = [information_gain(data, feature) for feature in features]\n",
    "        \n",
    "        # Choose the feature with the highest information gain\n",
    "        best_feature_index = np.argmax(info_gains)\n",
    "        best_feature = features[best_feature_index]\n",
    "        \n",
    "        # Create the tree structure\n",
    "        tree = {best_feature: {}}\n",
    "        \n",
    "        # Remove the feature with the highest information gain from the feature list\n",
    "        features = [i for i in features if i != best_feature]\n",
    "        \n",
    "        # Grow the tree\n",
    "        for value in np.unique(data[best_feature]):\n",
    "            value_subset = data[data[best_feature] == value]\n",
    "            subtree = id3(value_subset, original_data, features, target_attribute, parent_node_class)\n",
    "            tree[best_feature][value] = subtree\n",
    "        \n",
    "        return tree\n",
    "\n",
    "# Prepare the dataset and run ID3\n",
    "features = list(df.columns[:-1])\n",
    "decision_tree = id3(df, df, features)\n",
    "print(\"Decision Tree using ID3:\")\n",
    "print(decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b14b0-f182-4323-bcf0-541c0bdd4a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
